---
title: 'Section 1: dplyr'
author: "Jonathan Page"
output:
  github_document: 
    toc: TRUE
---

# Efficient R for Data Exploration

# Basic R Intro

The basic container of data in R is the vector. Vectors in R can be defined directly with
the function `c()`:
```{r}
x <- c(1, 2, 3, 4)
y <- c(5, 6)
x + y
```

Observe above that the two vectors are added element-wise and that the shorter
vector is recycled.

View a complete list of basic operators by running the following command:
```
?+.
```

Specify a seed for the pseudo-random number generator, take draws from two normally 
distributed random variables, and find their correlation.
```{r}
set.seed(101)

x <- rnorm(50)
y <- x + rnorm(50, mean = 25, sd = 0.1)

cor(x, y)
```

Look at summary statistics for these random variables:
```{r}
summary(x)
mean(x)
var(x)
sqrt(var(x))
sd(x)
```

# Basic visual exploration

Load `ggplot2` and plot scatterplots of the random variables:
```{r}
library(ggplot2)

df <- data.frame(cbind(x, y))
summary(df)

ggplot(df, aes(x, y)) + geom_point()
```

# Loading data

## SQLite example

The following [SQLite](https://www.sqlite.org/) database was downloaded from 
Kaggle at [https://www.kaggle.com/wendykan/lending-club-loan-data](https://www.kaggle.com/wendykan/lending-club-loan-data)

The data is available in SQLite format, so we will make use of the `RSQLite` package

```{r}
#install.packages("RSQLite")
library(RSQLite)
mydb <- dbConnect(RSQLite::SQLite(), "data/lending-club.sqlite")
dbListTables(mydb)
```

```{r}
dbListFields(mydb, "loan")
```

```{r}
dbGetQuery(mydb, "SELECT COUNT(*) FROM loan;")
```

```{r}
dbGetQuery(mydb, "SELECT addr_state, MIN(loan_amnt), MAX(loan_amnt), AVG(loan_amnt), COUNT(*) FROM loan GROUP BY addr_state;")
```

```{r}
loan10k <- dbGetQuery(mydb, "SELECT * FROM loan LIMIT 10000;")
# loan <- dbReadTable(mydb, "loan") # to grab the whole thing
dbDisconnect(mydb)
```

The above SQL, `SELECT * FROM loan LIMIT 10000;`, translates to requesting all
all fields (or columns) from the `loan` table, limiting our result to the first 10,000 records.

Summarize the loan data. Let's focus on two variables, the reported annual income, `annual_inc`, and the loan amount, `loan_amnt`.

```{r}
summary(loan10k$annual_inc)
```

```{r}
ggplot(loan10k, aes(annual_inc)) + geom_histogram() + geom_rug()
```

From the above plot, it should be clear the data is not normal. 
Let's take the log of annual income and loan amount.

```{r}
library(dplyr)
loan10k$ln_annual_inc <- log(loan10k$annual_inc) 
loan10k$ln_loan_amnt <- log(loan10k$loan_amnt) 
summary(loan10k$loan_amnt)
loan10k %>%
  ggplot(aes(annual_inc, loan_amnt)) + geom_point()
```

Compare the above scatterplot with the following on the log scale.
```{r}
ggplot(loan10k, aes(annual_inc, loan_amnt)) + geom_point() + scale_x_log10() + scale_y_log10()
```


Let's explore these by the stated purpose.
```{r}
loan10k %>% mutate(bad_status = loan_status %in% c("Charged Off", "Default")) %>%
ggplot(aes(ln_annual_inc, ln_loan_amnt, color = bad_status)) + geom_point(alpha = 0.2) + facet_wrap(~ purpose)
```

This analysis gave us an immediate sense of some important features of the data.

1. There are upper and lower caps on the loan amount.
2. The max loan amount is proportional to income for incomes below some amount.
3. The loan limit is a binding constraint for some loan purposes and not others.


## More dplyr

Let's make use of `dplyr` to group the loans by some income groups in the log scale.
The goal will be to make vertical slices and calculate the maximum loan amount for each slice.
We can then estimate the decision rule made by the bank. Note that there appear to be deviations above
the cap for some lower income levels. 

Group by income level:
```{r}
library(dplyr)
loan10k %>%
  group_by(loan_amnt) %>%
  summarize(max_loan = max(ln_loan_amnt), income = first(ln_annual_inc)) %>%
  ggplot(aes(income, max_loan)) + geom_point()
```

This first attempt did not use large enough bins of incomes. Let's add a variable that is coarser than `loan_amnt`:
```{r}
loan10k$income1k <- log(round(loan10k$annual_inc, -3))
loan10k$income10k <- log(round(loan10k$annual_inc, -4))
table(loan10k$income10k)
```

```{r}
loan10k %>%
  group_by(income1k) %>%
  summarize(max_loan = max(ln_loan_amnt), income = first(income1k)) %>%
  ggplot(aes(income, max_loan)) + geom_point()
```


The corner occurs at the lowest income at the overall max loan amount.
```{r}
loanmax <- max(loan10k$loan_amnt)
loanmax
```

```{r}
income_requirement <- loan10k %>%
  filter(loan_amnt == loanmax) %>%
  top_n(-1, annual_inc) %>%
  transmute(first_log_income = ln_annual_inc, first_income = annual_inc)
income_requirement
```

So, it seems that income must be above \$50,000 to qualify for the max loan amount of \$35,000. 

To calculate the income-based cutoff for those whose income is a binding constraint. Let's calculate slopes between each max and the corner of the binding constraint.

```{r}
maxes <- loan10k %>%
  filter(income1k < income_requirement$first_log_income) %>%
  group_by(income1k) %>%
  summarize(
    max_loan = max(ln_loan_amnt), 
    income = ln_annual_inc[which.max(ln_loan_amnt)],
    slope = (log(loanmax) - max_loan) / (income_requirement$first_log_income - income),
    intercept = income * slope - max_loan
    )
ggplot(maxes, aes(income, slope)) + geom_point()
```

and the intercept

```{r}
ggplot(maxes, aes(income, intercept)) + geom_point()
```

This looks pretty stable before log income of 10.5. A pragmatic approach is to take the median slope before
log income 10.5.

```{r}
decision_rule <- maxes %>%
  filter(income <= 10.5) %>%
  summarise(slope = median(slope), intercept = median(intercept))
decision_rule
```

## The decision boundary

So now we have enough information to define our best guess of the
business logic determining the max loan given an individual's income.

If the individual's income is less than 


\[log(\bar{y})= 4.5 + 1.4 * log(x)\]

or

\[\bar{y} = e^{4.5} x^{1.4}\]
